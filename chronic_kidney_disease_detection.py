# -*- coding: utf-8 -*-
"""Chronic_Kidney_Disease_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cTx25EuePfhV_tJBfta9ilwgGH7hG-B9

#                                 **DATA PROCESSING AND CLEANING **

---
"""

from google.colab import files
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder,StandardScaler
import tensorflow as tf
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
import pickle
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_validate,KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, chi2
import matplotlib.pyplot as plt

uploaded= files.upload()
df=pd.read_csv('kidney_disease.csv')
df.columns=df.columns.str.strip().str.lower().str.replace(' ','_')
missed=df.isnull().sum()
print(missed)
num_cols=df.select_dtypes(include=['float64','int64']).columns
for cols in num_cols:
  df[cols].fillna(df[cols].median(), inplace=True)
cat_cols =df.select_dtypes(include='object').columns
for cols in cat_cols:
  df[cols].fillna(df[cols].mode()[0], inplace=True)
  print("Remaining null values:\n",df.isnull().sum().sum())

"""**Descriptive statistical Analysis**"""

df.describe()
df.describe(include='object')
plt.figure(figsize=(8,4))
sns.histplot(df['age'],kde=True,bins=30,color='skyblue')
plt.title('Distribution of Age')
plt.xlabel('Age')
plt.ylabel('Density')
plt.show()
plt.figure(figsize=(6,4))
sns.countplot(data=df, x='classification',palette='Set2')
plt.title('Target Class Distribution')
plt.xlabel('Classification')
plt.ylabel('Count')
plt.show()
plt.figure(figsize=(8,4))
sns.boxplot(data=df, x='classification',y='age',palette='coolwarm')
plt.title('Age V/S Classification')
plt.xlabel('Classification')
plt.ylabel('Age')
plt.show()
count_cols=['bp','sg','bgr','bu','sc','sod','pot','hemo']
for col in count_cols:
  plt.figure(figsize=(8,4))
  sns.scatterplot(data=df, x='age', y=col, hue='classification')
  plt.title(f'Age V/S {col}')
  plt.show()
df_numeric=df.select_dtypes(include=['float64','int64'])
corr_matrix=df_numeric.corr()
plt.figure(figsize=(10,8))
sns.heatmap(corr_matrix,annot=True,cmap='coolwarm',fmt='.2f',linewidths=0.5)
plt.title("Correlation HeatMap")
plt.show()
print(df.columns.tolist())
df['classification']=df['classification'].replace(2,1)
print(np.unique(df['classification'],return_counts=True))
df['classification']=df['classification'].str.strip().str.lower()
df['classification']=df['classification'].replace({'ckd':1,'notckd':0})
print(np.unique(df['classification'],return_counts=True))
X=df.drop(['classification'],axis=1)
Y=df['classification']
X_train,X_test,Ytrain,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)
le=LabelEncoder()
for col in df.columns:
  if df[col].dtype=='object' and col !='classifictaion':
    df[col]=le.fit_transform(df[col].astype(str))
X=df.drop(['classification'],axis=1)
Y=df['classification']
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)
sc=StandardScaler()
X_train_scaled=sc.fit_transform(X_train)
X_test_scaled=sc.transform(X_test)
"""Logistic Regression"""
lgr=LogisticRegression()
lgr.fit(X_train_scaled,Y_train)
lgr_pred=lgr.predict(X_test_scaled)
print("Logistic Regression Results:")
print(confusion_matrix(Y_test,lgr_pred))
print(classification_report(Y_test,lgr_pred))

"""Decision TREEE"""
dtc=DecisionTreeClassifier()
dtc.fit(X_train_scaled,Y_train)

Y_pred_dtc=dtc.predict(X_test_scaled)
print("decision Tree Results:")
print(confusion_matrix(Y_test,Y_pred_dtc))
print(classification_report(Y_test,Y_pred_dtc))

"""Random Forest"""

rfc=RandomForestClassifier()
rfc.fit(X_train_scaled,Y_train)
Y_pred_rfc=rfc.predict(X_test_scaled)
print("Random forest Results:")
print(confusion_matrix(Y_test,Y_pred_rfc))
print(classification_report(Y_test,Y_pred_rfc))

sample_df=pd.DataFrame(columns=X.columns)
sample_df.loc[0]=[0.0]*len(X.columns)
sample_df.at[0,'age']=48
sample_df.at[0,'bp']=80
sample_df.at[0, 'sg'] = 1.02
sample_df.at[0, 'rbc'] = 1         
sample_df.at[0, 'pc'] = 1
sample_df.at[0, 'pcc'] = 0
sample_df.at[0, 'ba'] = 0
sample_df.at[0, 'htn'] = 1
sample_df.at[0, 'dm'] = 1
sample_df.at[0, 'appet'] = 1
sample_df.at[0, 'ane'] = 0

sample_scaled = sc.transform(sample_df)

print("Logistic Regression:", lgr.predict(sample_scaled)[0])
print("Decision Tree:", dtc.predict(sample_scaled)[0])
print("Random Forest:", rfc.predict(sample_scaled)[0])

"""Build and test ANN"""

ann=Sequential()
ann.add(Dense(units=64,activation='relu',input_dim=X_train_scaled.shape[1]))
ann.add(Dense(units=32,activation='relu'))
ann.add(Dense(units=1,activation='sigmoid'))
ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
ann.fit(X_train_scaled,Y_train,batch_size=32,epochs=10,validation_split=0.2)
Y_ann_pred=ann.predict(X_test_scaled)
Y_ann_pred=(Y_ann_pred>0.5).astype(int)
print("ANN Results:")
print(confusion_matrix(Y_test,Y_ann_pred))
print(classification_report(Y_test,Y_ann_pred))

sample_scaled=sc.transform(sample_df)
prediction=ann.predict(sample_scaled)
print("ANN prediction:",int (prediction[0][0]>0.5))

Y_pred_probs=ann.predict(X_test_scaled)
Y_pred=(Y_pred_probs>0.5).astype(int)

print("NN model Evaluation")
print(confusion_matrix(Y_test,Y_ann_pred))
print(classification_report(Y_test,Y_ann_pred))

Y_pred_lgr=lgr.predict(X_test_scaled)
print("Logistic regression")
print(confusion_matrix(Y_test,Y_pred_lgr))
print(classification_report(Y_test,Y_pred_lgr))

y_pred_dtc=dtc.predict(X_test_scaled)
print("Decision Tree")
print(confusion_matrix(Y_test,y_pred_dtc))
print(classification_report(Y_test,y_pred_dtc))

y_pred_rfc = rfc.predict(X_test_scaled)

print("ðŸ”¹ Random Forest Evaluation")
print(confusion_matrix(Y_test, y_pred_rfc))
print(classification_report(Y_test, y_pred_rfc))

def plot_confusion_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['no ckd', 'ckd'],
                yticklabels=['no ckd', 'ckd'])
    plt.xlabel('Predicted values')
    plt.ylabel('Actual values')
    plt.title(f'Confusion Matrix for {model_name}')
    plt.show()

# ----------- Predictions for each model -------------

y_pred_lr = lgr.predict(X_test_scaled)
plot_confusion_matrix(Y_test, y_pred_lr, 'Logistic Regression')
print('\n')

y_pred_dt = dtc.predict(X_test_scaled)
plot_confusion_matrix(Y_test, y_pred_dt, 'Decision Tree Classifier')
print('\n')

y_pred_rf = rfc.predict(X_test_scaled)
plot_confusion_matrix(Y_test, y_pred_rf, 'Random Forest Classifier')
print('\n')

y_pred_ann = (ann.predict(X_test_scaled) > 0.5).astype(int)
plot_confusion_matrix(Y_test, y_pred_ann, 'Artificial Neural Network (ANN)')
print('\n')

models=[('LogReg',LogisticRegression()),
        ('RF', RandomForestClassifier()),
        ('Decision Tree',DecisionTreeClassifier()),]
scoring=['accuracy','precision_weighted','recall_weighted','f1_weighted','roc_auc']
results=[]
names=[]
kfold=KFold(n_splits=5,shuffle=True,random_state=42)
for name, model in models:
  cv_results=cross_validate(model,X_train_scaled,Y_train,cv=kfold,scoring=scoring,return_train_score=False)
  df_cv=pd.DataFrame(cv_results)
  df_cv['model']=name
  results.append(df_cv)
  from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

y_pred_ann_probs = ann.predict(X_test_scaled)
y_pred_ann = (y_pred_ann_probs > 0.5).astype(int)

ann_scores = {
    'test_accuracy': [accuracy_score(Y_test, y_pred_ann)],
    'test_precision_weighted': [precision_score(Y_test, y_pred_ann, average='weighted')],
    'test_recall_weighted': [recall_score(Y_test, y_pred_ann, average='weighted')],
    'test_f1_weighted': [f1_score(Y_test, y_pred_ann, average='weighted')],
    'test_roc_auc': [roc_auc_score(Y_test, y_pred_ann)],
    'model': ['ANN']
}
results.append(pd.DataFrame(ann_scores))
final_results_df = pd.concat(results, ignore_index=True)

results_long = final_results_df.melt(id_vars='model', var_name='metric', value_name='value')
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(18, 10))
sns.set(font_scale=1.5)

sns.boxplot(x='model', y='value', hue='metric', data=results_long, palette='Set3')
plt.title('ðŸ“Š Comparison of Models by Classification Metrics', fontsize=20)
plt.xlabel('Model')
plt.ylabel('Scores')
plt.legend(bbox_to_anchor=(1.05, 1), loc=2)
plt.tight_layout()
plt.show()

"""MODEL TRAINED ON 25 FEatures
Extract only important features and give that features only to model for efficient input from user.
"""

df=pd.read_csv('kidney_disease.csv')
print("Original column names:\n",df.columns.tolist())

import seaborn as sns
import matplotlib.pyplot as plt

numeric_df = df.select_dtypes(include=['float64', 'int64'])
corr_matrix = numeric_df.corr()

plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

import seaborn as sns
plt.figure(figsize=(8, 4))
sns.boxplot(x='classification', y='bu', data=df)
plt.title('Blood Urea vs CKD Classification')

df_encoded = df.copy()

for col in df_encoded.select_dtypes(include='object').columns:
    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col].astype(str))

X = df_encoded.drop('classification', axis=1)
y = df_encoded['classification']

imputer = SimpleImputer(strategy='most_frequent') 
X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

chi_selector = SelectKBest(score_func=chi2, k='all')
chi_selector.fit(X_imputed, y)
chi_scores = pd.Series(chi_selector.scores_, index=X.columns)
chi_scores.sort_values(ascending=False).plot(kind='bar', figsize=(12, 5), title='Chi-Square Feature Scores')
plt.ylabel("Chi-Square Score")
plt.show()

df = pd.read_csv('kidney_disease.csv')
df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')
selected_features = [
    'blood_urea',
    'blood_glucose_random',
    'anemia',
    'coronary_artery_disease',
    'pus_cell',
    'red_blood_cells',
    'diabetes_mellitus',
    'pedal_edema'
]
rename_map = {
    'bu': 'blood_urea',
    'bgr': 'blood_glucose_random',
    'ane': 'anemia',
    'cad': 'coronary_artery_disease',
    'pc': 'pus_cell',
    'rbc': 'red_blood_cells',
    'dm': 'diabetes_mellitus',
    'pe': 'pedal_edema'
}
df = df.rename(columns=rename_map)
cols = selected_features + ['classification']
df = df[cols]
df['classification'] = df['classification'].str.strip().str.lower()
df['classification'] = df['classification'].replace({'ckd': 1, 'notckd': 0})
le = LabelEncoder()
for col in df.columns:
    if df[col].dtype == 'object':
        df[col] = le.fit_transform(df[col].astype(str))
imputer = SimpleImputer(strategy='most_frequent')
X = df.drop('classification', axis=1)
y = df['classification']
X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)
chi_selector = SelectKBest(score_func=chi2, k='all')
chi_selector.fit(X_imputed, y)
chi_scores = pd.Series(chi_selector.scores_, index=X.columns)
chi_scores.sort_values(ascending=False).plot(kind='bar', figsize=(10, 5), title='Chi-Square Feature Scores')
plt.ylabel("Chi2 Score")
plt.xlabel("Features")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print(X_selected.isnull().sum())

for col in X_selected.columns:
    if X_selected[col].dtype == 'object':
        X_selected[col].fillna(X_selected[col].mode()[0], inplace=True)
    else:
        X_selected[col].fillna(X_selected[col].median(), inplace=True)
print("Remaining nulls:", X_selected.isnull().sum().sum())  # Should be 0
le = LabelEncoder()
for col in X_selected.columns:
    if X_selected[col].dtype == 'object':
        X_selected[col] = le.fit_transform(X_selected[col].astype(str))

X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = LogisticRegression()
model.fit(X_train_scaled, y_train)

y_pred=model.predict(X_test_scaled)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))

with open('model.pkl', 'wb') as model_file:
    pickle.dump(model, model_file)

with open('scaler.pkl', 'wb') as scaler_file:
    pickle.dump(scaler, scaler_file)
